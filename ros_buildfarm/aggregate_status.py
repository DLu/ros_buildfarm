import os
import re
import yaml
import requests
import collections
from .config import get_index as get_config_index, get_release_build_files

"""

  Aggregate Status takes the yaml generated by the different CPU architectures (e.g. ros_lunar_default, ros_lunar_ds)
  and combines them into one yaml file per ROS distro. It also creates an English description of each package across
  all of the architectures. See examples below.

  Naming Conventions
   * distro refers to ROS Distro (e.g. indigo)
   * machine refers to different release builds (e.g. default, uxhf, dsv8)
   * os_name refers to the name of the Operating System (e.g. ubuntu, debian)
   * os_flavor refers to specific distros of the os (e.g. xenial, jessie)
   * cpu refers to the cpu architecture (or source), (e.g. i386, amd64, source)
   * candidate refers to different candidate builds, (e.g. build, test, main)
   * combo refers to the os_flavor + the cpu

  Example Descriptions:
   - released - All candidates have the same version number
   - waiting for new release - Build/test have the same version number, but there's nothing for main
   - waiting for re-release - Build/test have the same version number, but there's an older version for main
   - waiting for new/re-release - Build/test have the same version number, but there's either nothing or an older
                                  version for main
   - source builds, binary doesn't - If the source builds, but all the other cpus do not
   - does not build on X - If the source and some of the cpus build, but some do not
"""

CANDIDATES = ['build', 'test', 'main']  # Not imported from status_page to avoid potential circular dependency

YAML_FOLDER = 'http://repositories.ros.org/status_page/yaml/'
YAML_PATTERN = re.compile('<a href="(ros_(\w+)_(\w+).yaml)">')
VERSION_PATTERN = re.compile('([\d\-\.]+)\w+.*')


def _get_yaml_filenames(distro_key):
    """
       Scrape the YAML_FOLDER for filenames matching the YAML_PATTERN and return those with the matching distro
    """
    filenames = {}
    r = requests.get(YAML_FOLDER)
    for filename, distro, machine in YAML_PATTERN.findall(r.text):
        if distro != distro_key:
            continue
        filenames[distro, machine] = filename
    return filenames


def _dict_merge(dct, merge_dct):
    """
       Recursively merge merge_dct into dct
    """
    for k, v in merge_dct.iteritems():
        if (k in dct and isinstance(dct[k], dict) and isinstance(merge_dct[k], collections.Mapping)):
            _dict_merge(dct[k], merge_dct[k])
        else:
            dct[k] = merge_dct[k]


def get_aggregate_status(distro):
    """
       Load all of the individual yaml files and merge them into one giant dictionary.
    """
    status = {}
    for (distro, machine), filename in sorted(_get_yaml_filenames(distro).items()):
        print('  Loading {}/{}'.format(distro, machine))
        r = requests.get(YAML_FOLDER + filename)
        distro_status = yaml.load(r.text)
        _dict_merge(status, distro_status)
    return status


def _get_blacklist(build_file):
    """
       Load the package blacklist from the build_file.
       Returns a dictionary mapping the package name to
       a set of tuples of (os_name, os_flavor, cpu) that are blacklisted
    """
    blacklist = collections.defaultdict(set)
    for machine in build_file:
        machine_build_file = build_file[machine]
        if len(machine_build_file.package_blacklist) == 0:
            continue
        for pkg in machine_build_file.package_blacklist:
            for os_name, os_d in machine_build_file.targets.items():
                for os_flavor, fl_d in os_d.items():
                    for cpu in fl_d:
                        blacklist[pkg].add((os_name, os_flavor, cpu))
    return dict(blacklist)


def _get_expected_cpus(build_file):
    """
       Collect the expected CPU architectures, sorted by os_name and os_flavor.
       Returns a dictionary of dictionaries of sets, where
        * the first key is a os_name
        * the second key is a os_flavor
        * the set values are cpu architectures
    """
    C = collections.defaultdict(lambda: collections.defaultdict(set))
    for machine in build_file:
        machine_build_file = build_file[machine]
        for os_name, os_d in machine_build_file.targets.items():
            for os_flavor, fl_d in os_d.items():
                C[os_name][os_flavor].add('source')
                for cpu in fl_d:
                    C[os_name][os_flavor].add(cpu)
    return C


def _map_value_matches(M, key, value_list):
    """
       Convenience function for repeated operation to check if the
       dictionary M's value for the given key (which is a set)
       matches the set version of the list of values passed in.
    """
    return M[key] == set(value_list)


def _some_map_value_matches(M, value_list):
    """
       Returns true if some value in M
       matches the set version of the list of values passed in.
    """
    values = set(value_list)
    for key in M.keys():
        if M[key] == values:
            return True
    return False


def _some_other_value_matches(M, value_list, exclude):
    """
       Returns true if some value in M except the one with key=exclude
       matches the set version of the list of values passed in.
    """
    values = set(value_list)
    for key in M.keys():
        if key != exclude and M[key] == values:
            return True
    return False


def _no_overlap_in_values_and_none(M):
    if None not in M:
        return False
    # Assume M has two key/value pairs
    values0, values1 = M.values()
    return len(values0.intersection(values1)) == 0


def get_status_description(build_status, expected, blacklist, candidates=CANDIDATES, skip_source=False, debug=False):
    """
     build_status is a recursive structure that maps a specific build i.e.
      (os_name, os_flavor, cpu, candidate) to a version number
      If the version number is not present, then it is an error, i.e. version_number = None

     expected is data structure returned by _get_expected_cpus (constant across all packages)

     blacklist is a set of (os_name, os_flavor, cpu) that we don't expect to see (specific to this package)
    """

    # The first thing we do is reverse the mapping
    # version_map maps version to a list of (os_name, os_flavor, cpu, candidate)
    version_map = collections.defaultdict(list)

    # the following four structures map the version to either the os_name, os_flavor, etc
    os_map = collections.defaultdict(set)
    flavor_map = collections.defaultdict(set)
    cpu_map = collections.defaultdict(set)
    candidate_map = collections.defaultdict(set)

    # this maps the version to the os_flavor + cpu
    combo_map = collections.defaultdict(set)

    # build the reversed maps
    for os_name in expected:
        os_d = build_status.get(os_name, {})
        for os_flavor in expected[os_name]:
            fl_d = os_d.get(os_flavor, {})
            for cpu in expected[os_name][os_flavor]:
                if skip_source and cpu == 'source':
                    continue
                cpu_d = fl_d.get(cpu, {})
                for candidate in candidates:
                    version = None
                    if candidate in cpu_d:
                        version = VERSION_PATTERN.match(cpu_d[candidate]).group(1)
                    elif (os_name, os_flavor, cpu) in blacklist:
                        continue
                    os_map[version].add(os_name)
                    flavor_map[version].add(os_flavor)
                    cpu_map[version].add(cpu)
                    candidate_map[version].add(candidate)
                    combo_map[version].add(os_flavor + '/' + cpu)
                    version_map[version].append((os_name, os_flavor, cpu, candidate))

    # If there's only one version across all builds (and nothing is missing), then
    # this package is completely synced and released
    if len(version_map) == 1:
        return 'released'

    # If there are two different versions available
    if len(version_map) == 2:
        if _map_value_matches(candidate_map, None, ['main']):
            # one version for build/test, and all the main builds are None
            # this package hasn't been released yet, but it builds fine otherwise
            return 'waiting for new release'
        elif _some_map_value_matches(candidate_map, ['main']):
            # still one version for build/test, and some other version for main
            return 'waiting for re-release'

        if _some_map_value_matches(cpu_map, ['source']):
            cpu_version0, cpu_version1 = sorted(cpu_map.keys())
            # these versions could be (None, version) or (old_version, new_version)

            if cpu_version0 is None:
                return 'source builds, binary doesn\'t'
            elif _map_value_matches(cpu_map, cpu_version0, ['source']):
                # the source is the only thing that builds for the new version
                return 'source builds, binary doesn\'t'

        if _no_overlap_in_values_and_none(flavor_map):
            # if the thing that separates the working builds and nonworking builds is the os_flavor
            return 'does not build on ' + ', '.join(sorted(flavor_map[None]))
        elif _no_overlap_in_values_and_none(cpu_map):
            return 'does not build on ' + ', '.join(sorted(cpu_map[None]))
        elif _no_overlap_in_values_and_none(combo_map):
            return 'does not build on ' + ', '.join(sorted(combo_map[None]))

    # If there are three different versions availble
    elif len(version_map) == 3:
        if _map_value_matches(candidate_map, None, ['main']) and \
           _some_other_value_matches(candidate_map, ['main'], None):
            # This package builds fine in build/test, and has two different versions
            # in main, including None, then been released for some builds but not others
            return 'waiting for new/re-release'

    if None in version_map:
        # if some version is breaking (and doesn't match the above patterns)
        # gather all the flavor/cpu combos that are breaking
        broken_set = set([(os_flavor, cpu) for os_name, os_flavor, cpu, candidate in version_map[None]])
        if len(broken_set) == 1:
            os_flavor, cpu = list(broken_set)[0]
            return 'does not build on %s/%s' % (os_flavor, cpu)

    if candidates == CANDIDATES:
        sub_candidates = CANDIDATES[:-1]  # skip main
        status = get_status_description(build_status, expected, blacklist, sub_candidates)
        if status and status != 'released':
            return status

        status = get_status_description(build_status, expected, blacklist, sub_candidates, True)
        if status and status != 'released':
            return 'binary: ' + status

    if not debug:
        return
    print('{} versions ({})'.format(len(version_map), ', '.join(map(str, sorted(version_map)))))
    for name, M in [('os', os_map), ('flavor', flavor_map), ('cpu', cpu_map), ('candidate', candidate_map),
                    ('combo', combo_map)]:
        print(name)
        for version, values in M.iteritems():
            print('\t{}: {}'.format(version, ', '.join(values)))

    for version, M in sorted(version_map.items()):
        print(version, len(M))
        if version is None:
            print(M)
    print()


def build_aggregate_status(config_url, distro, output_dir='.'):
    print('Merging yaml files')
    aggregate_status = get_aggregate_status(distro)
    print('Classify statuses')
    config = get_config_index(config_url)
    build_file = get_release_build_files(config, distro)
    expected = _get_expected_cpus(build_file)
    blacklist = _get_blacklist(build_file)
    for pkg, entry in aggregate_status.items():
        description = get_status_description(entry['build_status'], expected, blacklist.get(pkg, set()))
        entry['description'] = description

    print('Write yaml file')
    yaml_filename = os.path.join(output_dir, '{}.yaml'.format(distro))
    yaml.safe_dump(aggregate_status, open(yaml_filename, 'w'), allow_unicode=True)
